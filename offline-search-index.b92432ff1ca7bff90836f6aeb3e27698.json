[{"body":"The quickest way to see vhs in action is to use the development Docker image in this repo to run a demo.\nPrerequisites The first step is to clone the VHS repository.\ngit clone https://github.com/rename-this/vhs.git You will need a working Docker installation to successfully execute the following commands. You should be able to install Docker from your favorite package manager, or you can see the Docker site for more details.\nOnce you have Docker set up and working, you can build the development container by changing directory into the repository you cloned and running:\n$ make dev This command will build and run a Docker container called vhs_dev that contains a standardized development environment for vhs. It includes the Go toolchain as well as other useful utilities such as curl and jq, among others. The vhs source tree that you cloned will be mounted inside the development container at /go/vhs for convenience. Additionally, if present, your Google Cloud SDK configuration folder (~/.config/gcloud) will be mounted in the container at /root/.config/gcloud and the GOOGLE_APPLICATION_CREDENTIALS environment variable will be set to /root/.config/gcloud/application_default_credentials.json. You may need to ensure that this file exists on your system or change this environment variable to point to your own GCS service account credentials before using the GCS functionality of vhs.\nDemo Setup Open a bash session on the container by running the following command in a terminal:\ndocker exec -it vhs_dev bash In your new bash session, run this script to start a simple echo server and a script that will make an HTTP request to the server once every second using curl.\ncd testdata \u0026\u0026 ./echo.bash This will generate some local HTTP traffic for vhs to capture.\nRun The Demo Open another bash session on the container in a new terminal:\ndocker exec -it vhs_dev bash In this new session, run the following command to build vhs and run it to capture our local HTTP traffic.\ngo build ./cmd/vhs \u0026\u0026 ./vhs --input \"tcp|http\" --output \"json|stdout\" --capture-response --address 0.0.0.0:1111 --middleware ./testdata/http_middleware.bash | jq -R \"fromjson | .body\" 2\u003e /dev/null The output should look something like this:\n\"hello, world 1594678195 [[hijacked 0]]\" \"hello, world 1594678195 [[hijacked 1]]\" \"hello, world 1594678196 [[hijacked 0]]\" \"hello, world 1594678196 [[hijacked 1]]\" \"hello, world 1594678197 [[hijacked 0]]\" \"hello, world 1594678197 [[hijacked 1]]\" \"hello, world 1594678198 [[hijacked 0]]\" \"hello, world 1594678198 [[hijacked 1]]\" \"hello, world 1594678199 [[hijacked 0]]\" \"hello, world 1594678199 [[hijacked 1]]\" \"hello, world 1594678200 [[hijacked 0]]\" Explanation of the Demo We can break down the demo command we just ran to get a better feel for how vhs works and what it can do:\ngo build ./cmd/vhs \u0026\u0026 ./vhs This portion of the command builds the vhs from the source tree and executes the resulting binary\n--input \"tcp|http\"  This portion of the command defines input portion of the data flow for this vhs session. Currently, only one source can be specified for a given vhs session.\nIn this case:\n tcp specifies the TCP data source. This source will capture TCP data off the network. http specifies the HTTP input format. This input format will extract HTTP requests and responses from the captured TCP data streams.  --output \"json|stdout\" This portion of the command specifies the output portion of the data flow for this vhs session. A vhs session may have any number of outputs.\nIn this case:\n json specifies the JSON output format. This output format will serialize the HTTP requests and responses into JSON. stdout specifies the standard output sink. This sink will print the data to the console.  --capture-response This flag tells the TCP input source to capture two-way network traffic (requests and responses) instead of one-way (requests only).\n--address 0.0.0.0:1111 This flag specifies the address and port from which vhs will capture traffic, in the form \u003cIP address\u003e:\u003cport\u003e.\n--middleware ./testdata/http_middleware.bash This flag specifies the middleware to run for this vhs session. Middleware enables users to modify or rewrite data as it passes through vhs from source to sink. The middleware specified here appends \" [[hijacked \u003cHTTP_MESSAGE_TYPE\u003e]]\" to the end of the http request or response body as it passes through vhs. More information on middleware can be found here.\n| jq -R \"fromjson | .body\" This portion of the command pipes the output of vhs to jq for filtering and pretty printing. This functionality is external to vhs. You can find more information on jq here.\n2\u003e /dev/null Discards stderr to keep the demo output clean.\nCommon Use Cases Capture live HTTP traffic to cloud storage ./vhs --input \"tcp|http\" --output \"json|gzip|gcs\" --address 0.0.0.0:80 --capture-response --gcs-bucket-name \u003csome_bucket\u003e --gcs-object-name \u003csome_object\u003e --flow-duration 2m\nThe above command will capture live HTTP traffic on port 80 for 2 minutes and save the captured data as gzipped JSON to Google Cloud Storage (GCS) in the specified bucket and object.\nGenerate HAR file from saved HTTP data ./vhs --input \"gcs|gzip|json --output \"har|stdout\" --gcs-bucket-name \u003csome_bucket\u003e --gcs-object-name \u003csome_object\u003e --flow-duration 15s \u003e harfile.json\nThe above command will “replay” saved HTTP data in gzipped JSON format from the specified GCS bucket and object and produce an HTTP Archive (HAR) file called harfile.json on the local filesystem.\nProvide live HTTP metrics ./vhs --input \"tcp|http\" --address 0.0.0.0:80 --capture-response --prometheus-address 0.0.0.0:8888 --flow-duration 60m\nThe above command will capture live HTTP traffic on port 80 and calculate RED metrics for the captured data in real time. These include metrics on request rate, error rate, and request duration. These metrics will be available on a Prometheus endpoint at port 8888. For more information on metrics see the vhs reference entry on metrics support. The command will run for 60 minutes.\n","excerpt":"The quickest way to see vhs in action is to use the development Docker …","ref":"/vhs/getting-started/","title":"Getting Started"},{"body":"Introduction vhs is designed for flexibility and operates on the concept of a data flow that originates with a source and terminates with one or more sinks. Sources may capture network data, read data from files, etc. Sinks may write data to cloud or local storage, standard output, or send data to other destinations. Along the way, data may pass through a series of input modifiers and formats and output modifiers and formats that transform the data. For more information on the technical implementation of vhs, see the architecture overview.\nExample vhs Command ./vhs --inputs \"tcp|http\" --outputs \"json|stdout\" --address 0.0.0.0:8080 --capture-response\nThis command captures two-way TCP data from the network on address 0.0.0.0 and port 8080, extracts HTTP requests and responses from the TCP data, formats them as JSON, and prints them to the standard output.\nSpecifying Inputs and Outputs The core command line flags for vhs are focused on defining the data flow that vhs will use for a recording/replay session. Inputs and outputs are specified in terms of a simple domain specific language that will be detailed in the following sections.\nInputs --input \"\u003csource|modifier(s)|format\u003e\"\nInputs are specified in a pipe-delimited (|), double-quoted string following the --input command line flag. This string must begin with a source, optionally contain modifiers, and end with an input format. The specified source originates a data stream that is modified by the specified modifiers and then formatted, or interpreted by the specified input format.\nIn the example command given above, the input specifier is --inputs \"tcp|http\" where tcp specifies the TCP source and http specifies the HTTP input format. This example does not use any input modifiers.\nOnly one input definition can be specified in a vhs session.\nSources The following sources are currently available:\n tcp file gcs (Google cloud storage) s3compat (S3 compatible cloud storage)  tcp The tcp source captures live TCP/IP network data. It uses the following additional command line flags for configuration:\n --address \u003cip address:port\u003e Required. Specifies the address and port on which vhs will listen. --capture-response Optional. If set, vhs captures requests and responses (2-way traffic).  file The file source reads data from a file on the local filesystem. It requires the following command line flag for configuration. This source reads a file from the filesystem and emits a raw stream of bytes to the modifiers and formats in the specified input chain. These modifiers and formats implement specific support for various file formats. JSON and gzipped-JSON files are currently supported by the available input modifiers and formats.\n --input_file \u003cpath to input file\u003e Required. Specifies the path to the input file to be read.  gcs The gcs source reads data from a Google Cloud Storage object. It requires the following command line flags for configuration. Note that the GCS source also requires Google Cloud authentication credentials to be present on the machine or in the container where vhs is run. The GOOGLE_APPLICATION_CREDENTIALS environment variable can be used to specify the location of the credentials file. For more information on GCS authentication, see Google’s documentation here.\n --gcs-bucket-name \u003cGCS bucket name\u003e Required. Name of bucket that contains the object to be read. --gcs-object-name \u003cobject name\u003e Required. Name of object to be read.  Note that this source also requires a JSON key file containing Google Cloud authentication credentials.\ns3compat The s3compat source reads from an object in an S3-compatible cloud storage location. It requires the following command line flags for configuration.\n --s3-compat-access-key \u003caccess key\u003e Required. Access key for S3 compatible storage. --s3-compat-secret-key \u003csecret key\u003e Required. Secret key for S3 compatible storage. --s3-compat-token \u003ctoken\u003e Required. Session token for S3 compatible storage. --s3-compat-secure Optional. This flag specifies encrypted transport (HTTPS). Default is true. --s3-compat-endpoint \u003cS3 URL\u003e Required. URL for S3-compatible storage. --s3-compat-bucket-name \u003cbucket name\u003e Required. Name of bucket that contains the object to be read. --s3-compat-object-name \u003cobject name\u003e Required. Name of object to be read.  Input Modifiers The following input modifiers are currently available in vhs:\n gzip  gzip The gzip input modifier uncompresses data that has been compressed in the gzip format. It is primarily for use with the file, gcs, and s3compat sources, enabling the reading of compressed files.\nInput Formats The following input formats are currently available in vhs:\n http json  http The http input format decodes the incoming data stream into HTTP requests and responses. This format is primarily intended for use with the tcp source.\njson The json input format interprets the incoming data stream as JSON. It is primarily intended for use with the file and cloud storage sources (gcs and s3compat) for processing data stored in a JSON file.\nOutputs --output \"\u003cformat|modifier(s)|sink\u003e\"\nOutputs are specified in a pipe-delimited (|), double-quoted string following the --output command line flag. The first element in the string must specify an output format, followed by a pipe character, followed by zero or more modifiers separated by pipe characters, followed by another pipe character, and ending with a sink specifier. The output chain works similarly to the input chain. The input format receives the data stream from the end of the input chain and formats or interprets the data. This data can then be modified by an output modifier before it leaves vhs through a sink.\nIn the example command given above, the output specifier is --outputs \"json|stdout\" where json specifies the JSON output format and stdout specifies the standard output sink. This example does not use any output modifiers.\nThe next sections will detail the currently available output format, modifiers, and sink in vhs. Each format, modifier, and sink may require additional configuration in the form of additional command line flags. These will be described where applicable.\nvhs supports an arbitrary number of outputs for any given session. Each output will receive the same data from the input chain.\nOutput Formats The following output formats are currently available in vhs:\n har (HTTP archive) json  har The har output format receives incoming data in the form of a stream of HTTP requests and responses and encodes it into the HTTP Archive (HAR) format. The output of this format can be saved to cloud storage or printed to standard output depending on the sink chosen by the user. For more information on the HTTP Archive format see the specification.\njson The json output format receives incoming data in the form of a stream of HTTP requests and responses and serializes those requests and responses to the JSON format. The output of this format can be saved to cloud storage or printed to standard output depending on the sink chosen by the user.\nOutput Modifiers The following output modifiers are currently available in vhs:\n gzip  gzip The gzip output modifier compresses the data passing through it into the gzip format. This can be used in conjunction with the stdout or cloud storage (gcs or s3compat) sinks to save compressed output data from vhs.\nSinks The following sinks are currently available in vhs:\n gcs (Google cloud storage) s3compat (S3-compatible cloud storage) stdout discard  gcs The gcs sink writes data to a Google Cloud Storage object. It requires the following command line flags for configuration. Note that the GCS sink also requires Google Cloud authentication credentials to be present on the machine or in the container where vhs is run. For more information on GCS authentication, see Google’s documentation here.\n --gcs-bucket-name \u003cGCS bucket name\u003e Required. Bucket name that contains the GCS object to be written to. --gcs-object-name \u003cobject name\u003e Required. Name of object to be read.  s3compat The s3compat sink writes to an object in an S3-compatible cloud storage location. It requires the following command line flags for configuration.\n --s3-compat-access-key \u003caccess key\u003e Required. Access key for S3 compatible storage. --s3-compat-secret-key \u003csecret key\u003e Required. Secret key for S3 compatible storage. --s3-compat-token \u003ctoken\u003e Required. Session token for S3 compatible storage. --s3-compat-secure Optional. This flag specifies encrypted transport (HTTPS). Default is true. --s3-compat-endpoint \u003cS3 URL\u003e Required. URL for S3-compatible storage. --s3-compat-bucket-name \u003cbucket name\u003e Required. Name of bucket that contains the object to be written. --s3-compat-object-name \u003cobject name\u003e Required. Name of object to be written.  stdout The stdout sink writes the data stream it receives to the standard output. This sink can be used in conjunction with shell redirection to save the output of vhs to a file on the local filesystem.\ndiscard The discard sink silently discards the data that is sent to it.\nMiddleware --middleware \u003cpath to middleware executable\u003e\nvhs optionally supports the use of user-supplied middleware to modify data as it passes through vhs. As an example, user supplied middleware could be utilized to remove sensitive user credentials from recorded HTTP data before saving it to cloud storage. Middleware, if used, is placed in the vhs data flow in the output chain between the output format and the output modifiers. It is implemented as a separate binary that will receive formatted data on the standard input and must write modified data on the standard output. A simple example middleware can be found here in the vhs repository.\nPrometheus metrics --prometheus-address \u003cip adddress:port\u003e\nvhs supports calculating metrics on HTTP exchanges captured live from the network. This facility can be used to non-invasively gather metrics for services utilizing HTTP. Specifying the --prometheus-address flag enables metrics support. Metrics support is implemented internally as an output format, and requires an input chain that includes the http input format. A typical command for utilizing the metrics support looks like this:\n./vhs --input \"tcp|http\" --address 0.0.0.0:80 --capture-response --prometheus-address 0.0.0.0:8080\nThis command will capture all http traffic on port 80, calculate metrics, and make them available at a /metrics endpoint on port 8080 of the machine/vm/container running vhs.\nThe provided metrics include measures of request rate, error rate, and request duration, sufficient for implementing the RED method of microservice monitoring. Metrics are supplied on a Prometheus endpoint. Request counts are available in a counter vector labeled with HTTP method, status code, and path. Errors counts are available by querying for HTTP error status codes, and timeouts are counted with empty status codes. Request durations are available in a summary vector with quantiles given in the table below. Durations are also labeled with HTTP method, status code, and path.\n   Quantile Error (+ / -)     50% 5%   75% 1%   90% 0.5%   95% 0.5%   99% 0.1%   99.9% 0.01%   99.99% 0.001%    Complete Command Line Flag Reference    Command line flag Description     –help, -h Show brief help for VHS.   –address string Address VHS will use to capture traffic. (default “0.0.0.0:80”)   –buffer-output Buffer output until the end of the flow.   –capture-response Capture the responses.   –debug Emit debug logging.   –debug-http-messages Emit all parsed HTTP messages as debug logs.   –debug-packets Emit all packets as debug logs.   –flow-duration duration The length of the running command. (default 10s)   –gcs-bucket-name string Bucket name for Google Cloud Storage   –gcs-object-name string Object name for Google Cloud Storage   –http-timeout duration A length of time after which an HTTP request is considered to have timed out. (default 30s)   –input string Input description.   –input-drain-duration duration A grace period to allow for a inputs to drain. (default 2s)   –input-file string Path to an input file   –middleware string A path to an executable that VHS will use as middleware.   –output strings Output description.   –profile-http-address string Expose profile data on this address.   –profile-path-cpu string Output CPU profile to this path.   –profile-path-memory string Output memory profile to this path.   –prometheus-address string Address for Prometheus metrics HTTP endpoint.   –s3-compat-access-key string Access key for S3-compatible storage.   –s3-compat-bucket-name string Bucket name for S3-compatible storage.   –s3-compat-endpoint string URL for S3-compatible storage.   –s3-compat-object-name string Object name for S3-compatible storage.   –s3-compat-secret-key string Secret key for S3-compatible storage.   –s3-compat-secure Encrypt communication for S3-compatible storage. (default true)   –s3-compat-token string Security token for S3-compatible storage.   –shutdown-duration duration A grace period to allow for a clean shutdown. (default 2s)   –tcp-timeout duration A length of time after which unused TCP connections are closed. (default 5m0s)    ","excerpt":"Introduction vhs is designed for flexibility and operates on the …","ref":"/vhs/reference/","title":"Reference"},{"body":"Introduction vhs is designed for flexibility and operates on the concept of a data flow that originates with a source and terminates with one or more sinks. Sources may capture network data, read data from files, etc. Sinks may write data to cloud or local storage, standard output, or send data to other destinations. Along the way, data may pass through a series of input modifiers and formats and output modifiers and formats that transform the data.\nMore architectural details coming soon.\n","excerpt":"Introduction vhs is designed for flexibility and operates on the …","ref":"/vhs/architecture/","title":"Architecture"},{"body":"Introduction to VHS VHS is a versatile tool for network traffic capture. VHS can be run as a command line tool or be deployed into your Kubernetes cluster as a sidecar, where it can capture traffic to and from your services. Captured traffic can be analyzed to produce live Prometheus metrics or saved for use in offline analysis, load testing, or whatever you can imagine.\n","excerpt":"Introduction to VHS VHS is a versatile tool for network traffic …","ref":"/vhs/","title":"VHS Documentation"},{"body":"","excerpt":"","ref":"/vhs/categories/","title":"Categories"},{"body":"","excerpt":"","ref":"/vhs/tags/","title":"Tags"}]